{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6e865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moon dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2e72794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 개별모델 내부에서 CV 적용해 Stacking하는 함수 구현\n",
    "def get_stacking_datasets(model, x_train_n, y_train_n, x_test_n, n_folds):\n",
    "    # CV하기 위해 K-fold 설정\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=42)\n",
    "    \n",
    "    # 최종 메타 모델이 사용할 학습 데이터 반환을 위해서 넘파이 배열을 0으로 만들어서 초기화\n",
    "    train_fold_pred = np.zeros((x_train_n.shape[0], 1)) # 2차원으로\n",
    "    test_pred = np.zeros((x_test_n.shape[0], n_folds))\n",
    "    print(model.__class__.__name__, '모델 시작')\n",
    "    \n",
    "    for folder_counter, (train_idx, valid_idx) in enumerate(kf.split(x_train_n)):\n",
    "        # 개별 모델 내부에서 학습하고 1개의 fold로 예측할 데이터 셋 추출\n",
    "        print(f\" Fold 횟수 : {folder_counter+1}\")\n",
    "        x_tr = x_train_n[train_idx]\n",
    "        y_tr = y_train_n[train_idx]\n",
    "        x_te = x_train_n[valid_idx]\n",
    "        \n",
    "        # 개별 모델이 학습한 후 1개의 fold데이터셋으로 예측값 반환 후 최종 메타모델이 학습할 데이터셋에 첨가\n",
    "        model.fit(x_tr, y_tr)\n",
    "        train_fold_pred[valid_idx, :] = model.predict(x_te).reshape(-1,1)\n",
    "        # 개별 모델이 원본 데이터셋의 검증 데이터셋을 기반으로 예측 결과값 반환 후 최종 메타모델이 검증할 데이터셋에 첨가\n",
    "        test_pred[:, folder_counter] = model.predict(x_test_n)\n",
    "    \n",
    "    # 개별모델안에서 테스트 데이터셋을 기반으로 예측한 결과값들 mean취해주고 2차원으로 바꾸어주기\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)\n",
    "    \n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "028d33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 개별 모델 정의\n",
    "knn_clf = KNeighborsClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "ab_clf = AdaBoostClassifier()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "# 최종 메타 모델 정의\n",
    "lr_final = LogisticRegression(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e48ce45b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m knn_train, knn_test \u001b[38;5;241m=\u001b[39m \u001b[43mget_stacking_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknn_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m rf_train, rf_test \u001b[38;5;241m=\u001b[39m get_stacking_datasets(rf_clf, x_train, y_train, x_test, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m ab_train, ab_test \u001b[38;5;241m=\u001b[39m get_stacking_datasets(ab_clf, x_train, y_train, x_test, \u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn [17], line 9\u001b[0m, in \u001b[0;36mget_stacking_datasets\u001b[0;34m(model, x_train_n, y_train_n, x_test_n, n_folds)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_stacking_datasets\u001b[39m(model, x_train_n, y_train_n, x_test_n, n_folds):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# CV하기 위해 K-fold 설정\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     kf \u001b[38;5;241m=\u001b[39m \u001b[43mKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# 최종 메타 모델이 사용할 학습 데이터 반환을 위해서 넘파이 배열을 0으로 만들어서 초기화\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     train_fold_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((x_train_n\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# 2차원으로\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/model_selection/_split.py:435\u001b[0m, in \u001b[0;36mKFold.__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m*\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/model_selection/_split.py:296\u001b[0m, in \u001b[0;36m_BaseKFold.__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshuffle must be True or False; got \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shuffle))\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shuffle \u001b[38;5;129;01mand\u001b[39;00m random_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# None is the default\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting a random_state has no effect since shuffle is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalse. You should leave \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_state to its default (None), or set shuffle=True.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    300\u001b[0m     )\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m=\u001b[39m n_splits\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle \u001b[38;5;241m=\u001b[39m shuffle\n",
      "\u001b[0;31mValueError\u001b[0m: Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True."
     ]
    }
   ],
   "source": [
    "knn_train, knn_test = get_stacking_datasets(knn_clf, x_train, y_train, x_test, 5)\n",
    "rf_train, rf_test = get_stacking_datasets(rf_clf, x_train, y_train, x_test, 5)\n",
    "ab_train, ab_test = get_stacking_datasets(ab_clf, x_train, y_train, x_test, 5)\n",
    "dt_train, dt_test = get_stacking_datasets(dt_clf, x_train, y_train, x_test, 5)\n",
    "\n",
    "# 개별모델이 생성한 학습/검증 데이터 최종 메타 모델이 학습/검증하도록 결합\n",
    "stack_final_x_train = np.concatenate((knn_train, rf_train, ab_train, dt_train), axis=1)\n",
    "stack_final_x_test = np.concatenate((knn_test, rf_test, ab_test, dt_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 최종 메타모델로 학습\n",
    "# 최종 메타모델 학습시 label은 원본 데이터의 label(y값)\n",
    "lr_final.fit(stack_final_x_train, y_train)\n",
    "stack_final_pred = lr_final.predict(stack_final_x_test)\n",
    "\n",
    "# 최종 메타모델 성능 평가(비교할 때 원본 데이터의 검증 데이터 label과 비교)\n",
    "print(f\"최종 메타모델 정확도 : {accuracy_score(y_test, stack_final_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
